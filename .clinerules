# QueryForge Project Rules

## MCP-First Principle - CRITICAL

**ALWAYS USE MCP TOOLS FIRST**: You must ALWAYS use the MCP server tools (`queryforge-local`) for ALL schema, field, example, and query operations. Direct file reading (read_file, search_files on JSON schemas) is FORBIDDEN except in these cases:
- MCP server is unreachable or returning errors
- You need to debug the MCP server implementation itself
- You are modifying schema files as part of development work

**If you read JSON files directly when MCP tools are available, you are violating project rules.**

## Query Building - MANDATORY

**CRITICAL**: When building queries for any security platform (CBC, Cortex, KQL, S1, CQL):

### 1. ALWAYS Consider Both Static AND Behavioral Detection

**Security Query Design Philosophy:**

When building security detection queries, you MUST consider BOTH approaches:

1. **Behavioral Detection (PREFERRED)** - Detects what threats DO:
   - Process execution patterns (e.g., web servers spawning shells)
   - Network connections from unusual processes
   - Privilege escalation attempts
   - Suspicious parent-child process relationships
   - Command-line patterns indicating malicious activity
   - **Higher fidelity, fewer false positives**

2. **Static Detection** - Detects what threats LOOK LIKE:
   - File extensions and paths
   - Hash values
   - File sizes and attributes
   - Registry keys or specific file locations
   - **More false positives, easier to evade**

**MANDATORY WORKFLOW for Threat Detection Queries:**

1. **Ask yourself:** "What BEHAVIOR indicates this threat?"
2. **Primary approach:** Build behavioral detection first
3. **Secondary approach:** Consider static indicators as supplementary
4. **Best practice:** Combine both when possible for defense-in-depth

**Examples:**

**Webshell Detection:**
- ✅ BEHAVIORAL: `web_server_process spawning command_shell` (HIGH FIDELITY)
- ❌ STATIC ONLY: `*.php files in /var/www/html` (HIGH FALSE POSITIVES)
- ✅ COMBINED: Both behavioral + suspicious file creation in web dirs

**Ransomware Detection:**
- ✅ BEHAVIORAL: `process creating many encrypted files + deleting originals` (HIGH FIDELITY)
- ❌ STATIC ONLY: `*.encrypted file extension` (HIGH FALSE POSITIVES)
- ✅ COMBINED: Both behavioral + known ransomware file markers

**Lateral Movement:**
- ✅ BEHAVIORAL: `remote process creation + network authentication` (HIGH FIDELITY)
- ❌ STATIC ONLY: `psexec.exe present on disk` (INCOMPLETE)
- ✅ COMBINED: Both behavioral + tool artifacts

**Why Behavioral Detection is Superior:**
- Catches threats during active exploitation
- Harder for attackers to evade
- Works against zero-day threats
- Detects technique, not specific implementation
- Lower false positive rate for high-fidelity detections

**When to Use Static Detection:**
- Known IOCs (hashes, domains, IPs)
- Compliance requirements (file inventory)
- Post-incident forensics
- As supplementary evidence alongside behavioral detection

### 2. Check for Exact Example Query Matches FIRST

Before building a query from scratch, check if an exact example query exists:

**When to return example queries directly:**
- User's natural language request matches an example query title, description, or use case
- No specific filters, fields, or customizations are requested
- The example query is production-ready and validated

**Example matching criteria:**
- Match on key phrases in the user's request (e.g., "files written to removable media")
- Match on security use cases (e.g., "data exfiltration", "lateral movement")
- Match on event types or behaviors described

**When NOT to use example queries:**
- User specifies custom filters (device names, IP addresses, specific values)
- User requests modifications to the query structure
- User asks for a subset of fields or different aggregations
- Multiple examples match and user intent is ambiguous

**If an exact match is found:** Return the production-ready example query as-is, including all its complexity (aggregations, transformations, etc.)

### 2. Use MCP Tools for Schema Discovery

Before building any query, use the appropriate MCP tools to discover schema information:

**Dataset/Table Discovery:**
- `cbc_list_datasets` / `cbr_list_datasets` / `cortex_list_datasets` / `kql_list_datasets` / `cql_list_datasets` / `s1_list_datasets`
- Use `query_intent` parameter for semantic search to find relevant datasets

**Field Discovery:**
- `cbc_get_fields` / `cbr_get_fields` / `cortex_get_fields` / `kql_get_fields` / `cql_get_fields` / `s1_get_fields`
- Use `query_intent` parameter to filter semantically relevant fields
- NEVER read schema JSON files directly unless MCP server is unavailable

**Example Query Discovery:**
- `cbc_get_examples` / `cbr_get_examples` / `cortex_get_examples` / `kql_get_examples` / `cql_get_examples` / `s1_get_examples`
- Use `query_intent` or `category` parameters to find relevant examples

### 3. ALWAYS Use MCP Query Builder Tools

You MUST use the appropriate MCP query builder tool for the platform.

**DEFAULT: Use Combined Build+Validate Tools** (RECOMMENDED for all queries):

- **Carbon Black Cloud**: `cbc_build_query_validated`
- **Cortex XDR**: `cortex_build_query_validated`
- **Microsoft Defender/KQL**: `kql_build_query_validated`
- **SentinelOne**: `s1_build_query_validated`
- **CrowdStrike**: `cql_build_query_validated`

**Benefits:**
- ✅ **10x faster** - Single API call instead of build → validate → rebuild cycles
- ✅ **Automatic corrections** - Built-in retry logic applies fixes without LLM reasoning delays
- ✅ **Validation included** - Returns both the query and validation results
- ✅ **Caching enabled** - Repeated/similar queries validate instantly from cache

**Alternative: Traditional Two-Step Tools** (only if you need fine-grained control):
- `cbc_build_query` → `cbc_validate_query`
- `cortex_build_query` → `cortex_validate_query`
- `kql_build_query` → `kql_validate_query`
- `s1_build_query` → `s1_validate_query`
- `cql_build_query` → `cql_validate_query`

### 2. NEVER Manually Write Query Syntax

Do NOT manually construct query strings. The query builders:
- Use the correct field schema from actual data sources
- Apply proper operator normalization from schema definitions
- Handle value formatting and escaping correctly
- Generate syntactically valid platform-specific queries

### 3. Correct Field Schema Usage

The query builders ensure correct field names are used:
- **SentinelOne**: `src.process.name` (NOT `SrcProcName`)
- **Cortex XDR**: `actor_process_image_name` (NOT `ActorProcessImageName`)
- **KQL**: Table-specific column names
- **CBC**: Documented field names from schema

### 4. Query Building Parameters

Use the appropriate parameters when calling build tools:

- **natural_language_intent**: When user describes what to find in plain language
- **filters**: For structured field/operator/value conditions
- **dataset/table/search_type**: To specify the data source
- **time_range/time_window**: For temporal filtering

## Examples

### ✅ CORRECT Approach
```
Use s1_build_query tool:
{
  "dataset": "files",
  "natural_language_intent": "browser downloads from chrome or firefox"
}
```

### ❌ INCORRECT Approach
```
Manually writing:
"SrcProcName = 'chrome.exe'" 
# WRONG! This uses incorrect field schema in S1 and bypasses the query builder
```

## Why This Matters

1. **Field Schema Accuracy**: Platforms update their schemas; the query builder uses the current schema
2. **Operator Validation**: Each platform has specific operators; the builder validates and normalizes them
3. **Value Escaping**: Different platforms require different escaping (quotes, backslashes, etc.)
4. **Syntax Correctness**: Platform-specific syntax rules are enforced by the builder

## Query Development Workflow

### DEFAULT: Use Combined Build+Validate Tools

The combined build+validate tools automatically handle validation and retries in a single operation:

**Example Usage:**
```
result = call_tool("s1_build_query_validated", {
  "dataset": "processes",
  "natural_language_intent": "chrome processes"
})

# Result includes:
# - result["query"]: Validated query string
# - result["validation"]: Full validation results
# - result["retry_count"]: Number of corrections applied (0 if perfect first try)
# - result["corrections_applied"]: List of automatic fixes
```

**Standard Workflow:**
1. Understand the user's intent
2. Identify the appropriate platform and dataset
3. Call the combined `*_build_query_validated` tool with parameters
4. The tool automatically:
   - Builds the initial query
   - Validates it
   - Applies corrections if needed (up to 3 retries)
   - Returns the validated query
5. Present the validated query to the user

### Alternative: Traditional Two-Step Workflow (Advanced Use Only)

If you need fine-grained control over each step, you can use the traditional approach:

1. Understand the user's intent
2. Identify the appropriate platform and dataset
3. Use the corresponding MCP `*_build_query` tool
4. **MANDATORY: Validate the query** using the corresponding `*_validate_query` tool
5. **If validation fails (valid=False)**: Fix and retry (see validation workflow below)
6. Present the validated query to the user

Never skip step 3 by manually writing queries!
**Never skip step 4 - validation is MANDATORY!**

## Query Validation - MANDATORY

### CRITICAL: Always Validate Queries Before Presenting to Users

After building a query with any `*_build_query` tool, you MUST:

1. **Immediately call the corresponding validation tool**:
   - `cbc_build_query` → `cbc_validate_query`
   - `cortex_build_query` → `cortex_validate_query`
   - `kql_build_query` → `kql_validate_query`
   - `s1_build_query` → `s1_validate_query`

2. **Pass both the query and metadata to validation**:
   ```
   # Build result includes both query and metadata
   build_result = call_tool("s1_build_query", {...})

   # Pass both to validation
   validate_result = call_tool("s1_validate_query", {
       "query": build_result["query"],
       "metadata": build_result["metadata"]
   })
   ```

3. **Check the validation result**:
   - If `valid=True`: Safe to present the query to the user
   - If `valid=False`: **You MUST fix the query before presenting it**

### Validation Failure Retry Workflow - REQUIRED

When `valid=False` (validation fails), you MUST:

1. **Read ALL errors** in `validation_results`:
   ```json
   {
     "valid": false,
     "validation_results": {
       "syntax": {"errors": [...]},
       "schema": {"errors": [...]},
       "operators": {"errors": [...]},
       "performance": {"errors": [...]},
       "best_practices": {"errors": [...]}
     }
   }
   ```

2. **Extract suggestions from each error**:
   - Each error has a `suggestion` field with actionable guidance
   - Example: "Field 'process_name' not found. Did you mean: tgt.process.name?"

3. **Call the build tool again with corrections**:
   - Fix field names based on suggestions
   - Adjust dataset/table if needed
   - Correct operators as suggested

4. **Validate the corrected query**:
   - Call the validate tool again on the new query

5. **Repeat until valid=True**:
   - Continue fixing and validating until the query passes
   - Do NOT give up after one retry - keep fixing until valid

6. **NEVER present invalid queries to users**:
   - Invalid queries may fail at runtime
   - They may return incorrect results
   - They may have security or performance issues

### Example Retry Pattern

```python
# Initial build
result = call_tool("s1_build_query", {
    "dataset": "processes",
    "filters": [{"field": "process_name", "value": "cmd.exe"}]
})

# Validate
validation = call_tool("s1_validate_query", {
    "query": result["query"],
    "metadata": result["metadata"]
})

# Check if valid
if not validation["valid"]:
    # Extract error
    error = validation["validation_results"]["schema"]["errors"][0]
    # error["message"]: "Field 'process_name' not found"
    # error["suggestion"]: "Did you mean: tgt.process.name?"

    # Retry with correction
    result = call_tool("s1_build_query", {
        "dataset": "processes",
        "filters": [{"field": "tgt.process.name", "value": "cmd.exe"}]
    })

    # Validate again
    validation = call_tool("s1_validate_query", {
        "query": result["query"],
        "metadata": result["metadata"]
    })
    # Now validation["valid"] should be True
```

### Handling Warnings

- **Warnings** (when `valid=True` but warnings exist) should be shown to the user
- Warnings indicate potential performance or best practice issues
- The query is valid but may benefit from optimization
- Present warnings to the user along with the query

### Summary

**MANDATORY RULES**:
1. ✅ ALWAYS validate after building
2. ✅ ALWAYS retry with corrections when valid=False
3. ✅ ALWAYS repeat until valid=True
4. ❌ NEVER present invalid queries to users
5. ❌ NEVER skip validation
6. ❌ NEVER give up after one retry - keep fixing until valid
